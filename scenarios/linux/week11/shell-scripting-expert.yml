mission:
  id: "shell-scripting-expert"
  title: "Expert Shell Scripting: System Tools and Automation"
  difficulty: "expert"
  description: |
    Build sophisticated system administration tools using advanced bash features.
    Create deployment automation, log analyzers, and system health monitors that
    professionals use in production environments.

    Master expert-level scripting for real-world system administration!
  estimated_time: "60 minutes"
  xp_reward: 750
  tags:
    - "shell-scripting"
    - "bash"
    - "automation"
    - "system-admin"
    - "expert"
    - "week11"

environment:
  runtime: "docker"
  base_image: "ubuntu:22.04"
  setup: |
    apt-get update && apt-get install -y \
      bash \
      coreutils \
      procps \
      curl \
      jq

steps:
  - id: "log-analyzer"
    description: |
      **Building a Log Analyzer**

      **Task:** Create a comprehensive log analysis tool.

      ```bash
      mkdir -p ~/expert_scripting
      cd ~/expert_scripting

      # Create sample logs
      cat > application.log << 'EOF'
      2024-01-09 10:00:15 INFO User login: alice from 192.168.1.100
      2024-01-09 10:01:22 ERROR Database connection failed: timeout
      2024-01-09 10:01:25 INFO Retry attempt 1
      2024-01-09 10:01:30 ERROR Database connection failed: timeout
      2024-01-09 10:02:10 INFO User login: bob from 192.168.1.101
      2024-01-09 10:03:45 WARNING High memory usage: 85%
      2024-01-09 10:04:12 ERROR API request failed: 500 Internal Server Error
      2024-01-09 10:05:00 INFO User logout: alice
      2024-01-09 10:06:33 ERROR Database connection failed: timeout
      2024-01-09 10:07:15 WARNING Disk usage above 80%
      EOF

      cat > log_analyzer.sh << 'EOF'
      #!/bin/bash
      # Advanced log analyzer

      set -euo pipefail

      LOG_FILE="${1:-application.log}"
      REPORT_FILE="log_analysis_report.txt"

      # Initialize report
      cat > "$REPORT_FILE" << 'HEADER'
      ========================================
      LOG ANALYSIS REPORT
      ========================================
      HEADER

      echo "Generated: $(date)" >> "$REPORT_FILE"
      echo "Log file: $LOG_FILE" >> "$REPORT_FILE"
      echo "" >> "$REPORT_FILE"

      # Overall statistics
      {
        echo "=== OVERALL STATISTICS ==="
        echo "Total lines: $(wc -l < "$LOG_FILE")"
        echo "ERROR count: $(grep -c "ERROR" "$LOG_FILE" || echo 0)"
        echo "WARNING count: $(grep -c "WARNING" "$LOG_FILE" || echo 0)"
        echo "INFO count: $(grep -c "INFO" "$LOG_FILE" || echo 0)"
        echo ""
      } >> "$REPORT_FILE"

      # Error breakdown
      {
        echo "=== ERROR BREAKDOWN ==="
        grep "ERROR" "$LOG_FILE" | \
          awk -F': ' '{print $2}' | \
          sort | uniq -c | sort -rn | \
          awk '{printf "  %3d Ã— %s\n", $1, substr($0, index($0,$2))}'
        echo ""
      } >> "$REPORT_FILE"

      # Timeline analysis
      {
        echo "=== EVENTS PER HOUR ==="
        awk '{print $2}' "$LOG_FILE" | \
          cut -d: -f1 | \
          sort | uniq -c | \
          awk '{printf "  %s:00 - %3d events\n", $2, $1}'
        echo ""
      } >> "$REPORT_FILE"

      # IP analysis
      {
        echo "=== UNIQUE IPS ==="
        grep -oP '\d+\.\d+\.\d+\.\d+' "$LOG_FILE" | \
          sort -u | \
          awk '{printf "  %s\n", $1}'
        echo ""
      } >> "$REPORT_FILE"

      # Critical issues
      {
        echo "=== CRITICAL ISSUES (Repeated Errors) ==="
        grep "ERROR" "$LOG_FILE" | \
          awk -F': ' '{print $2}' | \
          sort | uniq -c | \
          awk '$1 >= 2 {printf "  âš ï¸  %s (occurred %d times)\n", substr($0, index($0,$2)), $1}'
        echo ""
      } >> "$REPORT_FILE"

      echo "Analysis complete: $REPORT_FILE"
      EOF

      chmod +x log_analyzer.sh

      echo "Log Analyzer Output" > analyzer_demo.txt
      echo "===================" >> analyzer_demo.txt
      ./log_analyzer.sh >> analyzer_demo.txt
      echo "" >> analyzer_demo.txt
      echo "Generated report:" >> analyzer_demo.txt
      cat log_analysis_report.txt >> analyzer_demo.txt

      cat analyzer_demo.txt
      ```
    hint: |
      Combine grep, awk, sort, uniq for analysis. Use awk -F to split on custom
      delimiters. Build reports incrementally, testing each section separately.
    validation:
      - type: "file-exists"
        path: "~/expert_scripting/analyzer_demo.txt"

  - id: "deployment-automation"
    description: |
      **Deployment Automation Script**

      **Task:** Create a deployment automation tool.

      ```bash
      cat > deploy.sh << 'EOF'
      #!/bin/bash
      # Deployment automation script

      set -euo pipefail

      # Configuration
      APP_NAME="myapp"
      DEPLOY_DIR="/tmp/deploy"
      BACKUP_DIR="/tmp/backups"
      ROLLBACK_ENABLED=true

      # Colors
      GREEN='\033[0;32m'
      RED='\033[0;31m'
      YELLOW='\033[0;33m'
      NC='\033[0m'

      # Logging
      log() {
        echo -e "${GREEN}[$(date '+%H:%M:%S')]${NC} $*"
      }

      error() {
        echo -e "${RED}[ERROR]${NC} $*" >&2
      }

      warn() {
        echo -e "${YELLOW}[WARN]${NC} $*"
      }

      # Pre-flight checks
      preflight_checks() {
        log "Running pre-flight checks..."

        # Check dependencies
        local deps=(tar gzip)
        for cmd in "${deps[@]}"; do
          if ! command -v "$cmd" &> /dev/null; then
            error "Missing dependency: $cmd"
            return 1
          fi
        done

        # Check directories
        mkdir -p "$DEPLOY_DIR" "$BACKUP_DIR"

        log "âœ“ Pre-flight checks passed"
        return 0
      }

      # Backup current version
      backup_current() {
        log "Creating backup..."

        local backup_name="${APP_NAME}_$(date +%Y%m%d_%H%M%S).tar.gz"

        if [ -d "$DEPLOY_DIR/$APP_NAME" ]; then
          tar -czf "$BACKUP_DIR/$backup_name" -C "$DEPLOY_DIR" "$APP_NAME" 2>/dev/null
          log "âœ“ Backup created: $backup_name"
          echo "$backup_name" > "$BACKUP_DIR/latest_backup.txt"
        else
          warn "No existing deployment to backup"
        fi

        return 0
      }

      # Deploy new version
      deploy_new_version() {
        log "Deploying new version..."

        # Create new app directory
        mkdir -p "$DEPLOY_DIR/$APP_NAME"

        # Simulate deployment
        echo "version: 2.0" > "$DEPLOY_DIR/$APP_NAME/version.txt"
        echo "deployed: $(date)" >> "$DEPLOY_DIR/$APP_NAME/version.txt"

        log "âœ“ Deployment complete"
        return 0
      }

      # Health check
      health_check() {
        log "Running health check..."

        if [ -f "$DEPLOY_DIR/$APP_NAME/version.txt" ]; then
          log "âœ“ Health check passed"
          return 0
        else
          error "Health check failed"
          return 1
        fi
      }

      # Rollback
      rollback() {
        warn "Initiating rollback..."

        if [ ! -f "$BACKUP_DIR/latest_backup.txt" ]; then
          error "No backup available for rollback"
          return 1
        fi

        local backup_file=$(cat "$BACKUP_DIR/latest_backup.txt")

        rm -rf "$DEPLOY_DIR/$APP_NAME"
        tar -xzf "$BACKUP_DIR/$backup_file" -C "$DEPLOY_DIR" 2>/dev/null

        log "âœ“ Rollback complete"
        return 0
      }

      # Main deployment flow
      main() {
        log "Starting deployment of $APP_NAME"
        echo ""

        # Pre-flight
        if ! preflight_checks; then
          error "Pre-flight checks failed"
          exit 1
        fi

        # Backup
        if ! backup_current; then
          error "Backup failed"
          exit 1
        fi

        # Deploy
        if ! deploy_new_version; then
          error "Deployment failed"
          if [ "$ROLLBACK_ENABLED" = true ]; then
            rollback
          fi
          exit 1
        fi

        # Health check
        if ! health_check; then
          error "Health check failed"
          if [ "$ROLLBACK_ENABLED" = true ]; then
            rollback
            exit 1
          fi
        fi

        echo ""
        log "ðŸŽ‰ Deployment successful!"
        log "Application: $APP_NAME"
        log "Location: $DEPLOY_DIR/$APP_NAME"
      }

      main "$@"
      EOF

      chmod +x deploy.sh

      echo "Deployment Script Output" > deploy_demo.txt
      echo "========================" >> deploy_demo.txt
      ./deploy.sh >> deploy_demo.txt 2>&1

      cat deploy_demo.txt
      ```
    hint: |
      Deployment scripts need: pre-flight checks, backups, health checks, and
      rollback capability. Always validate before executing destructive operations.
    validation:
      - type: "file-exists"
        path: "~/expert_scripting/deploy_demo.txt"

  - id: "system-health-monitor"
    description: |
      **Comprehensive System Health Monitor**

      **Task:** Build a complete system health monitoring tool.

      ```bash
      cat > health_monitor.sh << 'EOF'
      #!/bin/bash
      # System health monitoring tool

      set -euo pipefail

      # Thresholds
      declare -A THRESHOLDS=(
        [cpu]=80
        [memory]=80
        [disk]=80
        [load]=4.0
      )

      # Status tracking
      declare -A STATUS
      declare -a ALERTS=()

      # Get CPU usage
      check_cpu() {
        local cpu_idle=$(top -bn1 | grep "Cpu(s)" | awk '{print $8}' | cut -d'%' -f1 2>/dev/null || echo "100")
        local cpu_used=$(echo "100 - $cpu_idle" | bc 2>/dev/null || echo "0")
        local cpu_int=${cpu_used%.*}

        if (( cpu_int > THRESHOLDS[cpu] )); then
          STATUS[cpu]="CRITICAL"
          ALERTS+=("CPU usage at ${cpu_int}%")
        else
          STATUS[cpu]="OK"
        fi

        echo "$cpu_int"
      }

      # Get memory usage
      check_memory() {
        local mem_info=$(free | grep Mem)
        local total=$(echo "$mem_info" | awk '{print $2}')
        local used=$(echo "$mem_info" | awk '{print $3}')
        local percent=$((used * 100 / total))

        if (( percent > THRESHOLDS[memory] )); then
          STATUS[memory]="CRITICAL"
          ALERTS+=("Memory usage at ${percent}%")
        else
          STATUS[memory]="OK"
        fi

        echo "$percent"
      }

      # Get disk usage
      check_disk() {
        local disk_percent=$(df -h / | awk 'NR==2 {print $5}' | tr -d '%')

        if (( disk_percent > THRESHOLDS[disk] )); then
          STATUS[disk]="CRITICAL"
          ALERTS+=("Disk usage at ${disk_percent}%")
        else
          STATUS[disk]="OK"
        fi

        echo "$disk_percent"
      }

      # Get load average
      check_load() {
        local load=$(uptime | awk -F'load average:' '{print $2}' | awk '{print $1}' | tr -d ',')
        STATUS[load]="OK"
        echo "$load"
      }

      # Generate JSON report
      generate_json_report() {
        local cpu_val="$1"
        local mem_val="$2"
        local disk_val="$3"
        local load_val="$4"

        cat << JSON
      {
        "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
        "hostname": "$(hostname)",
        "metrics": {
          "cpu_percent": $cpu_val,
          "memory_percent": $mem_val,
          "disk_percent": $disk_val,
          "load_average": $load_val
        },
        "status": {
          "cpu": "${STATUS[cpu]}",
          "memory": "${STATUS[memory]}",
          "disk": "${STATUS[disk]}",
          "load": "${STATUS[load]}"
        },
        "alerts": [
      $(printf '    "%s"' "${ALERTS[@]}" | paste -sd, -)
        ]
      }
      JSON
      }

      # Main
      main() {
        echo "=== SYSTEM HEALTH MONITOR ==="
        echo "Time: $(date)"
        echo ""

        # Collect metrics
        local cpu=$(check_cpu)
        local mem=$(check_memory)
        local disk=$(check_disk)
        local load=$(check_load)

        # Display
        printf "CPU Usage:    %3d%% [%s]\n" "$cpu" "${STATUS[cpu]}"
        printf "Memory Usage: %3d%% [%s]\n" "$mem" "${STATUS[memory]}"
        printf "Disk Usage:   %3d%% [%s]\n" "$disk" "${STATUS[disk]}"
        printf "Load Average: %s [%s]\n" "$load" "${STATUS[load]}"

        # Alerts
        if [ ${#ALERTS[@]} -gt 0 ]; then
          echo ""
          echo "âš ï¸  ALERTS:"
          for alert in "${ALERTS[@]}"; do
            echo "  - $alert"
          done
        fi

        # JSON report
        echo ""
        echo "JSON Report:"
        generate_json_report "$cpu" "$mem" "$disk" "$load"
      }

      main "$@"
      EOF

      chmod +x health_monitor.sh

      echo "Health Monitor Output" > health_demo.txt
      echo "=====================" >> health_demo.txt
      ./health_monitor.sh >> health_demo.txt 2>&1

      cat health_demo.txt
      ```
    hint: |
      Use associative arrays for structured data. Collect all metrics first,
      then generate reports. Support multiple output formats (text, JSON).
    validation:
      - type: "file-exists"
        path: "~/expert_scripting/health_demo.txt"

  - id: "expert-integration"
    description: |
      **Building an Integration Framework**

      **Task:** Create a tool that ties everything together.

      ```bash
      cat > ops_toolkit.sh << 'EOF'
      #!/bin/bash
      # Operations toolkit - master script

      set -euo pipefail

      TOOLKIT_VERSION="1.0.0"

      usage() {
        cat << 'USAGE'
      Operations Toolkit v1.0.0
      ==========================

      Usage: ops_toolkit.sh <command> [options]

      Commands:
        analyze <logfile>    - Analyze log files
        deploy               - Run deployment
        health               - System health check
        report               - Generate full report

      Options:
        -h, --help          - Show this help
        -v, --version       - Show version

      Examples:
        ops_toolkit.sh analyze application.log
        ops_toolkit.sh health
        ops_toolkit.sh report
      USAGE
      }

      # Generate comprehensive report
      generate_report() {
        local report="ops_report_$(date +%Y%m%d_%H%M%S).txt"

        {
          echo "========================================"
          echo "  OPERATIONS REPORT"
          echo "========================================"
          echo "Generated: $(date)"
          echo "Hostname: $(hostname)"
          echo ""

          echo "=== SYSTEM HEALTH ==="
          if [ -x "./health_monitor.sh" ]; then
            ./health_monitor.sh 2>&1 | head -10
          else
            echo "Health monitor not available"
          fi

          echo ""
          echo "=== DISK USAGE ==="
          df -h / | tail -1

          echo ""
          echo "=== TOP PROCESSES ==="
          ps aux --sort=-%cpu | head -4 | tail -3

          echo ""
          echo "=== RECOMMENDATIONS ==="
          echo "âœ“ Regular backups configured"
          echo "âœ“ Monitoring active"
          echo "âš  Review disk usage monthly"

          echo ""
          echo "Report saved: $report"
        } | tee "$report"
      }

      # Main dispatcher
      main() {
        case "${1:-}" in
          analyze)
            shift
            if [ -x "./log_analyzer.sh" ]; then
              ./log_analyzer.sh "$@"
            else
              echo "Log analyzer not available"
              exit 1
            fi
            ;;
          deploy)
            if [ -x "./deploy.sh" ]; then
              ./deploy.sh
            else
              echo "Deploy script not available"
              exit 1
            fi
            ;;
          health)
            if [ -x "./health_monitor.sh" ]; then
              ./health_monitor.sh
            else
              echo "Health monitor not available"
              exit 1
            fi
            ;;
          report)
            generate_report
            ;;
          -h|--help)
            usage
            ;;
          -v|--version)
            echo "Operations Toolkit v$TOOLKIT_VERSION"
            ;;
          *)
            echo "Unknown command: ${1:-}"
            echo ""
            usage
            exit 1
            ;;
        esac
      }

      main "$@"
      EOF

      chmod +x ops_toolkit.sh

      echo "Operations Toolkit Demo" > toolkit_demo.txt
      echo "=======================" >> toolkit_demo.txt
      echo "" >> toolkit_demo.txt
      echo "Running: ops_toolkit.sh report" >> toolkit_demo.txt
      echo "" >> toolkit_demo.txt
      ./ops_toolkit.sh report >> toolkit_demo.txt 2>&1

      cat toolkit_demo.txt
      ```

      **Congratulations!** You've mastered expert shell scripting!

      **You built:**
      - Log analyzer with statistics and patterns
      - Deployment automation with rollback
      - System health monitor with alerts
      - Integrated operations toolkit

      **Expert techniques:**
      - Comprehensive error handling
      - Structured logging
      - Multi-format output (text, JSON)
      - Backup and rollback strategies
      - Health checks and validation
      - Integration frameworks

      **Production checklist:**
      âœ“ Error handling (set -euo pipefail)
      âœ“ Logging and timestamps
      âœ“ Input validation
      âœ“ Backup before changes
      âœ“ Health checks
      âœ“ Rollback capability
      âœ“ Documentation
      âœ“ Exit codes

      You can now build production-grade system tools!
    hint: |
      Master scripts dispatch to specialized tools. Use consistent interfaces,
      proper exit codes, and comprehensive error handling throughout.
    validation:
      - type: "file-exists"
        path: "~/expert_scripting/toolkit_demo.txt"
