mission:
  id: "command-basics-beginner"
  title: "Essential Linux Commands"
  difficulty: "beginner"
  description: |
    Master the most commonly used Linux commands for text processing, file
    searching, and basic system operations. Learn grep, wc, sort, uniq, and more.

    Build your command-line toolkit with essential utilities!
  estimated_time: "30 minutes"
  xp_reward: 250
  tags:
    - "commands"
    - "grep"
    - "basics"
    - "text-processing"
    - "week4"

environment:
  runtime: "docker"
  base_image: "ubuntu:22.04"
  setup: |
    apt-get update && apt-get install -y \
      coreutils \
      grep

steps:
  - id: "searching-with-grep"
    description: |
      **Searching Text with grep**

      `grep` searches for patterns in files.

      **Basic usage:**
      ```bash
      grep "pattern" file.txt         # Search for pattern
      grep "error" log.txt            # Find lines with "error"
      grep -i "error" log.txt         # Case-insensitive
      grep -n "error" log.txt         # Show line numbers
      grep -v "success" log.txt       # Invert (lines WITHOUT pattern)
      grep -r "pattern" directory/    # Recursive search
      ```

      **Useful combinations:**
      ```bash
      grep -in "error" file.txt       # Case-insensitive + line numbers
      grep -c "pattern" file.txt      # Count matching lines
      ```

      **Task:** Practice grep.

      ```bash
      mkdir -p ~/commands
      cd ~/commands

      # Create test file
      cat > log.txt << 'EOF'
      INFO: Application started
      ERROR: Failed to connect to database
      INFO: Retrying connection
      ERROR: Connection timeout
      INFO: User logged in
      WARNING: Low disk space
      INFO: Request processed
      ERROR: Invalid input
      EOF

      echo "Searching with grep" > grep_demo.txt
      echo "===================" >> grep_demo.txt
      echo "" >> grep_demo.txt

      echo "All ERROR lines:" >> grep_demo.txt
      grep "ERROR" log.txt >> grep_demo.txt

      echo "" >> grep_demo.txt
      echo "ERROR lines with line numbers:" >> grep_demo.txt
      grep -n "ERROR" log.txt >> grep_demo.txt

      echo "" >> grep_demo.txt
      echo "Count of ERROR lines:" >> grep_demo.txt
      grep -c "ERROR" log.txt >> grep_demo.txt

      cat grep_demo.txt
      ```
    hint: |
      grep is case-sensitive by default. Use -i for case-insensitive search.
      Use -n to see line numbers, -v to invert the match.
    validation:
      - type: "file-exists"
        path: "~/commands/grep_demo.txt"

  - id: "counting-with-wc"
    description: |
      **Counting with wc**

      `wc` (word count) counts lines, words, and characters.

      **Basic usage:**
      ```bash
      wc file.txt             # Lines, words, characters
      wc -l file.txt          # Count lines only
      wc -w file.txt          # Count words only
      wc -c file.txt          # Count bytes only
      wc -m file.txt          # Count characters
      ```

      **Common patterns:**
      ```bash
      ls | wc -l              # Count files in directory
      grep "pattern" file | wc -l  # Count matching lines
      cat file | wc          # Count from stdin
      ```

      **Task:** Practice wc.

      ```bash
      # Create test files
      cat > document.txt << 'EOF'
      This is a sample document.
      It has multiple lines.
      And multiple words in each line.
      We will count them all.
      EOF

      echo "Counting with wc" > wc_demo.txt
      echo "================" >> wc_demo.txt
      echo "" >> wc_demo.txt

      echo "Full count (lines words bytes):" >> wc_demo.txt
      wc document.txt >> wc_demo.txt

      echo "" >> wc_demo.txt
      echo "Line count only:" >> wc_demo.txt
      wc -l document.txt >> wc_demo.txt

      echo "" >> wc_demo.txt
      echo "Word count only:" >> wc_demo.txt
      wc -w document.txt >> wc_demo.txt

      echo "" >> wc_demo.txt
      echo "How many ERROR lines in log.txt:" >> wc_demo.txt
      grep "ERROR" log.txt | wc -l >> wc_demo.txt

      cat wc_demo.txt
      ```
    hint: |
      wc output format is: lines words bytes filename. Use -l for just lines,
      which is most common. Combine with grep to count matching lines.
    validation:
      - type: "file-exists"
        path: "~/commands/wc_demo.txt"

  - id: "sorting-with-sort"
    description: |
      **Sorting Lines with sort**

      `sort` arranges lines alphabetically or numerically.

      **Basic usage:**
      ```bash
      sort file.txt           # Sort alphabetically
      sort -r file.txt        # Reverse sort
      sort -n file.txt        # Numeric sort
      sort -u file.txt        # Unique (remove duplicates)
      sort -k2 file.txt       # Sort by 2nd column
      ```

      **Useful combinations:**
      ```bash
      sort -nr file.txt       # Numeric, reversed
      sort -t: -k3 file.txt   # Use : as delimiter, sort by 3rd field
      ```

      **Task:** Practice sort.

      ```bash
      # Create test data
      cat > numbers.txt << 'EOF'
      10
      2
      30
      1
      20
      EOF

      cat > words.txt << 'EOF'
      zebra
      apple
      banana
      apple
      cherry
      EOF

      echo "Sorting with sort" > sort_demo.txt
      echo "=================" >> sort_demo.txt
      echo "" >> sort_demo.txt

      echo "Alphabetical sort:" >> sort_demo.txt
      sort words.txt >> sort_demo.txt

      echo "" >> sort_demo.txt
      echo "Numeric sort:" >> sort_demo.txt
      sort -n numbers.txt >> sort_demo.txt

      echo "" >> sort_demo.txt
      echo "Unique words only (-u):" >> sort_demo.txt
      sort -u words.txt >> sort_demo.txt

      echo "" >> sort_demo.txt
      echo "Reverse sort:" >> sort_demo.txt
      sort -r words.txt >> sort_demo.txt

      cat sort_demo.txt
      ```
    hint: |
      Use -n for numeric sort (otherwise "10" comes before "2"). Use -u to
      remove duplicates while sorting. -r reverses the order.
    validation:
      - type: "file-exists"
        path: "~/commands/sort_demo.txt"

  - id: "unique-with-uniq"
    description: |
      **Finding Unique Lines with uniq**

      `uniq` removes duplicate adjacent lines (usually used after sort).

      **Basic usage:**
      ```bash
      uniq file.txt           # Remove adjacent duplicates
      uniq -c file.txt        # Count occurrences
      uniq -d file.txt        # Show only duplicates
      uniq -u file.txt        # Show only unique lines
      ```

      **IMPORTANT: uniq only removes adjacent duplicates!**
      ```bash
      sort file.txt | uniq    # Correct way
      uniq file.txt           # Might miss duplicates
      ```

      **Task:** Practice uniq.

      ```bash
      cat > items.txt << 'EOF'
      apple
      banana
      apple
      cherry
      banana
      apple
      EOF

      echo "Using uniq" > uniq_demo.txt
      echo "==========" >> uniq_demo.txt
      echo "" >> uniq_demo.txt

      echo "Original file:" >> uniq_demo.txt
      cat items.txt >> uniq_demo.txt

      echo "" >> uniq_demo.txt
      echo "After sort | uniq:" >> uniq_demo.txt
      sort items.txt | uniq >> uniq_demo.txt

      echo "" >> uniq_demo.txt
      echo "Count of each item (-c):" >> uniq_demo.txt
      sort items.txt | uniq -c >> uniq_demo.txt

      echo "" >> uniq_demo.txt
      echo "Most common items (sort by count):" >> uniq_demo.txt
      sort items.txt | uniq -c | sort -rn >> uniq_demo.txt

      cat uniq_demo.txt
      ```
    hint: |
      Always use 'sort | uniq' together! uniq only removes adjacent duplicates,
      so sort first. Use -c to count occurrences.
    validation:
      - type: "file-exists"
        path: "~/commands/uniq_demo.txt"

  - id: "cutting-columns"
    description: |
      **Extracting Columns with cut**

      `cut` extracts columns from text.

      **Basic usage:**
      ```bash
      cut -d: -f1 file.txt    # Use : as delimiter, get field 1
      cut -d, -f2,3 file.txt  # Comma delimiter, fields 2 and 3
      cut -c1-5 file.txt      # Characters 1 through 5
      ```

      **Common use cases:**
      ```bash
      # Extract usernames from /etc/passwd
      cut -d: -f1 /etc/passwd

      # Extract specific CSV columns
      cut -d, -f1,3 data.csv
      ```

      **Task:** Practice cut.

      ```bash
      # Create CSV data
      cat > users.csv << 'EOF'
      alice,25,Engineer
      bob,30,Manager
      carol,28,Designer
      dave,35,Developer
      EOF

      echo "Extracting Columns with cut" > cut_demo.txt
      echo "============================" >> cut_demo.txt
      echo "" >> cut_demo.txt

      echo "Full data:" >> cut_demo.txt
      cat users.csv >> cut_demo.txt

      echo "" >> cut_demo.txt
      echo "Names only (field 1):" >> cut_demo.txt
      cut -d, -f1 users.csv >> cut_demo.txt

      echo "" >> cut_demo.txt
      echo "Names and jobs (fields 1,3):" >> cut_demo.txt
      cut -d, -f1,3 users.csv >> cut_demo.txt

      cat cut_demo.txt
      ```
    hint: |
      -d specifies the delimiter (default is tab). -f specifies which fields
      to extract. Use -c for character positions instead of fields.
    validation:
      - type: "file-exists"
        path: "~/commands/cut_demo.txt"

  - id: "combining-commands"
    description: |
      **Combining Commands with Pipes**

      Pipe (|) sends output of one command as input to another.

      **Basic piping:**
      ```bash
      command1 | command2     # Output of 1 â†’ input of 2
      cat file | grep "pattern" | wc -l  # Chain multiple
      ```

      **Practical examples:**
      ```bash
      # Find most common words
      cat file.txt | tr ' ' '\n' | sort | uniq -c | sort -rn | head

      # List largest files
      ls -l | sort -k5 -rn | head

      # Count unique IPs in log
      grep "IP" log | cut -d: -f2 | sort -u | wc -l
      ```

      **Task:** Build command pipelines.

      ```bash
      echo "Command Pipelines" > pipelines.txt
      echo "=================" >> pipelines.txt
      echo "" >> pipelines.txt

      echo "Example 1: Find unique ERROR types in log:" >> pipelines.txt
      grep "ERROR" log.txt | cut -d: -f2 | sort -u >> pipelines.txt

      echo "" >> pipelines.txt
      echo "Example 2: Count each log level:" >> pipelines.txt
      cat log.txt | cut -d: -f1 | sort | uniq -c | sort -rn >> pipelines.txt

      echo "" >> pipelines.txt
      echo "Example 3: Find all lines in log without ERROR or INFO:" >> pipelines.txt
      grep -v "ERROR" log.txt | grep -v "INFO" >> pipelines.txt

      cat pipelines.txt
      ```

      **Congratulations!** You've mastered essential Linux commands!

      **You learned:**
      - grep: Search for patterns in text
      - wc: Count lines, words, characters
      - sort: Arrange lines alphabetically/numerically
      - uniq: Remove duplicate lines
      - cut: Extract columns from text
      - Pipes: Chain commands together

      **Common patterns:**
      ```bash
      grep pattern file | wc -l           # Count matches
      sort file | uniq                    # Remove duplicates
      sort file | uniq -c | sort -rn      # Count and rank
      cut -d, -f1,3 file.csv              # Extract CSV columns
      ```

      **Best practices:**
      - Use pipes to chain simple commands
      - Test each command separately first
      - Read data left to right in pipeline
      - Combine simple tools for complex tasks

      You now have powerful text processing skills!
    hint: |
      Think of pipes as an assembly line: each command does one thing, passes
      result to next. Build complex operations from simple pieces!
    validation:
      - type: "file-exists"
        path: "~/commands/pipelines.txt"
